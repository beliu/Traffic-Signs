{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries are imported\n"
     ]
    }
   ],
   "source": [
    "### Import the libraries to be used for the project\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.variables import Variable\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "print('Libraries are imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper Functions are Created\n"
     ]
    }
   ],
   "source": [
    "### The following are wrapper or helper functions\n",
    "def get_data():\n",
    "    '''Load data from a pickle file'''\n",
    "    \n",
    "    training_file = \"traffic-signs-data/train.p\" # The training and testing file paths\n",
    "    testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "    with open(training_file, mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open(testing_file, mode='rb') as f:\n",
    "        test = pickle.load(f)\n",
    "\n",
    "    X_train, y_train = train['features'], train['labels']\n",
    "    X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def make_gray(features):\n",
    "    '''Create an array to hold a grayscale image vector for each image sample in the dataset'''\n",
    "    \n",
    "    # Create an array to hold a grayscale image vector for each image sample in the training dataset\n",
    "    X_train_gray = np.empty([*features.shape[0:3], 1], np.float32)\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        X_train_gray[i, :, :, 0] = cv2.cvtColor(features[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return X_train_gray\n",
    "\n",
    "\n",
    "def get_summary(X_train, y_train, X_test, y_test):\n",
    "    '''Get some basic information about the data'''\n",
    "    \n",
    "    # TODO: number of training examples\n",
    "    n_train = X_train.shape[0]\n",
    "\n",
    "    # TODO: number of testing examples\n",
    "    n_test = X_test.shape[0]\n",
    "\n",
    "    # TODO: what's the shape of an image?\n",
    "    image_shape = X_train.shape[1:4]\n",
    "\n",
    "    # TODO: how many classes are in the dataset\n",
    "    n_classes = max(y_train) + 1\n",
    "    \n",
    "    return n_train, n_test, image_shape, n_classes\n",
    "\n",
    "\n",
    "def print_images(data, indices=[]):\n",
    "    '''Show each image provided in data'''\n",
    "    \n",
    "    # For a single image\n",
    "    if len(data.shape) <= 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        # For grayscale images\n",
    "        if (data.shape[-1] == 1):\n",
    "            data = data[:, :, 0]\n",
    "            ax.imshow(data, cmap='gray')\n",
    "        # For color images\n",
    "        else:\n",
    "            ax.imshow(data)\n",
    "        if len(indices) > 0:\n",
    "            print(indices[0])\n",
    "        plt.show()\n",
    "    # For multiple images    \n",
    "    elif len(data.shape) >= 4:\n",
    "        for d in range(len(data)):\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            # For grayscale images\n",
    "            if (data[d].shape[-1] == 1):\n",
    "                ax.imshow(data[d, :, :, 0], cmap='gray')\n",
    "            # For color images\n",
    "            else:\n",
    "                ax.imshow(data[d])\n",
    "            if len(indices) > 0:\n",
    "                print(indices[d])\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "def print_class(features, labels, class_no, image_idx):\n",
    "    '''Print images by the class provided'''\n",
    "    \n",
    "    # For one image label\n",
    "    if len(labels) == 1:\n",
    "        indices_by_class = np.where(labels == class_no)\n",
    "    else:\n",
    "        indices_by_class = np.where(labels == class_no)[0]\n",
    "    features_by_class = features[indices_by_class]\n",
    "    images = features_by_class[image_idx]\n",
    "    print_images(images, image_idx)\n",
    "    \n",
    "\n",
    "def count_classes(data, n_classes):\n",
    "    '''Return a count of the number of images per class, and the starting index of each class'''\n",
    "    \n",
    "    class_no = 0\n",
    "    count = 0\n",
    "    class_count = np.zeros((n_classes), np.int32)\n",
    "    class_idx = np.zeros((n_classes), np.int32)\n",
    "\n",
    "    for d in data:\n",
    "        class_count[d] += 1\n",
    "    \n",
    "    for c in range(1, len(class_count)):\n",
    "        class_idx[c] = class_idx[c-1] + class_count[c-1]\n",
    "        \n",
    "    return class_count, class_idx\n",
    "\n",
    "\n",
    "def make_subset(features, labels, n_classes=43, track_no=30, threshold=600, reduction=4):\n",
    "    '''\n",
    "        This function reduces the dataset size by randomly selecting whole tracks to remove from classes with\n",
    "        a larger number of image samples. The track structure of the images of the subset is kept intact.\n",
    "        \n",
    "        Arguments:\n",
    "        track_no - the number of samples in a single track of traffic sign images\n",
    "        treshold - classes whose number samples exceed this number will be reduced\n",
    "        reduction - 1 over this number is the proportion of the dataset we are including in the subset\n",
    "    '''\n",
    "    # Get the original count of the samples per class in the dataset\n",
    "    class_count, class_idx = count_classes(labels, n_classes)\n",
    "    # Get the number of tracks per class\n",
    "    num_tracks = class_count/track_no\n",
    "    num_tracks = num_tracks.astype(np.int32)\n",
    "    \n",
    "    x_subset = np.copy(features)\n",
    "    y_subset = np.copy(labels)\n",
    "    delete_range = np.array([]) # The range of indicies of the samples we are removing from the dataset copy\n",
    "    del_perct = 1.0-1.0/reduction # The proportion of the dataset we are removing\n",
    "    \n",
    "    # For each class, remove del_perct proportion of tracks from the dataset copy if the number of samples\n",
    "    # in the class exceeds the threshold\n",
    "    for n in range(len(num_tracks)):\n",
    "        if num_tracks[n]*track_no > threshold:\n",
    "            # Randomly select the tracks to delete from the copy of the dataset\n",
    "            a = np.arange(num_tracks[n])\n",
    "            a = np.random.permutation(a)\n",
    "            end = int(del_perct*len(a)) \n",
    "            a = a[0:end] # We only want to remove del_perct proportion of the number of tracks\n",
    "            a = np.sort(a).astype(np.int32)\n",
    "            for i in a:\n",
    "                # This is the indices range in the dataset of the track we are removing.\n",
    "                delete_range = np.append(delete_range, \n",
    "                                         range(i*track_no + class_idx[n], (i+1)*track_no + class_idx[n]))\n",
    "                \n",
    "    x_subset = np.delete(x_subset, delete_range, axis=0)\n",
    "    y_subset = np.delete(y_subset, delete_range, axis=0)     \n",
    "    \n",
    "    return x_subset, y_subset\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    '''Normalize the data'''\n",
    "    \n",
    "    data_norm = data/255.0\n",
    "    \n",
    "    return data_norm\n",
    "            \n",
    "\n",
    "def add_synthetic_data(features, labels, tfms=['fliplr', 'rotate', 'blur'], max_angle=20, max_sigma=2):\n",
    "    '''\n",
    "        Add Synthetic Data to the dataset. This function groups the data together by class.\n",
    "        \n",
    "        Arguments:\n",
    "        tfms - a list of the operations desired for adding synthetic data. Options include:\n",
    "                'fliplr' - flip left/right\n",
    "                'flipud' - flip up/down\n",
    "                'rotate' - rotate the image cw or ccw\n",
    "                'blur' - add Gaussian blur\n",
    "        max_angle - the maximum angle in degrees by which an image will be rotated cw or ccw\n",
    "        max_sigma - the maximum sigma value for Gaussian blurring\n",
    "    '''\n",
    "    \n",
    "    # Create the arrays to store the new dataset with synthetic data added\n",
    "    class_count, class_idx = count_classes(labels, max(labels)+1)\n",
    "    new_len = (len(tfms) + 1)*len(features)\n",
    "    X_mod = np.empty((new_len, *features.shape[1:]), features.dtype)\n",
    "    y_mod = np.empty((new_len, *labels.shape[1:]), labels.dtype)\n",
    "    index = 0\n",
    "    \n",
    "    for c in range(len(class_count)):\n",
    "        # Copy the class' original unmodified dataset\n",
    "        X_mod[index:index + class_count[c]] = np.copy(features[class_idx[c]:class_idx[c] + class_count[c]])\n",
    "        y_mod[index:index + class_count[c]] = np.copy(labels[class_idx[c]:class_idx[c] + class_count[c]])\n",
    "        index += class_count[c]\n",
    "        \n",
    "        # Add the transformations to each image sample in the class, keeping the class samples together\n",
    "        for op in tfms:\n",
    "            for i in range(class_idx[c], class_idx[c] + class_count[c]):\n",
    "                if op == 'fliplr':\n",
    "                    X_mod[index] = np.fliplr(features[i])\n",
    "                    y_mod[index] = labels[i]\n",
    "                if op == 'flipud':\n",
    "                    X_mod[index] = np.flipud(features[i])\n",
    "                    y_mod[index] = labels[i]\n",
    "                if op == 'rotate':\n",
    "                    angle = random.uniform(-max_angle, max_angle) # Randomly selected angle between max_angle\n",
    "                    X_mod[index] = scipy.ndimage.interpolation.rotate(features[i], angle, reshape=False) \n",
    "                    y_mod[index] = labels[i]\n",
    "                if op == 'blur':\n",
    "                    sigma = random.uniform(0., max_sigma) # Randomly selected sigma less than max_sigma\n",
    "                    X_mod[index] = scipy.ndimage.filters.gaussian_filter(features[i], sigma)\n",
    "                    y_mod[index] = labels[i]\n",
    "                index += 1   \n",
    "\n",
    "    return X_mod, y_mod\n",
    "\n",
    "\n",
    "def make_encoder(labels):\n",
    "    '''Creates a binarizer encoder based on the labels'''\n",
    "    \n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(labels)\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "\n",
    "def one_hot_transform(labels, encoder):\n",
    "    '''Applys the one hot transform to the input labels'''\n",
    "    \n",
    "    train_labels = encoder.transform(labels)\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "\n",
    "    return train_labels\n",
    "\n",
    "def select_data(features, labels, subset_len=1290):\n",
    "    '''Randomly select a track from each class'''\n",
    "    \n",
    "    _, train_features, _, train_labels = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=subset_len,\n",
    "        random_state=832289,\n",
    "        stratify = labels)\n",
    "    \n",
    "    return train_features, train_labels\n",
    "\n",
    "\n",
    "def make_train_test(features, labels, op='random_split', n_classes=43, split_size=0.20, track_size=30):\n",
    "    '''\n",
    "        Make a training and validation dataset\n",
    "        \n",
    "        Arguments:\n",
    "        op - How to split the data. Options include:\n",
    "                random_split - Randomly split into training and validation sets using train_test_split\n",
    "                track_split - Randomly select one track per class for validation\n",
    "    '''\n",
    "    \n",
    "    # Get randomized datasets for training and validation using sklearn's train_test_split. \n",
    "    # This does not keep the track structure intact.\n",
    "    if op == 'random_split':\n",
    "        # Get randomized datasets for training and validation\n",
    "        train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "            features,\n",
    "            labels,\n",
    "            test_size=split_size,\n",
    "            random_state=832289,\n",
    "            stratify = labels)\n",
    "        \n",
    "    elif op == 'track_split':\n",
    "        class_count, class_idx = count_classes(labels, n_classes)\n",
    "        \n",
    "        # Copy the features and labels because we're going to delete the validation set from them\n",
    "        train_features = np.copy(features)\n",
    "        train_labels = np.copy(labels)\n",
    "        valid_features = np.empty((len(class_count)*track_size, *train_features[0].shape), train_features.dtype)\n",
    "        if len(labels.shape) == 1:\n",
    "            valid_labels = np.empty((len(class_count)*track_size), train_labels.dtype)\n",
    "        else:\n",
    "            valid_labels = np.empty((len(class_count)*track_size, labels.shape[-1]), train_labels.dtype)\n",
    "        delete_range = np.empty((len(class_count), track_size), np.int32)\n",
    "        num_tracks = class_count/track_size\n",
    "        num_tracks = num_tracks.astype(np.int32)\n",
    "        \n",
    "        # Randomly select a track from each class and add to the validation set\n",
    "        for t in range(len(num_tracks)):        \n",
    "            track_num = np.random.randint(num_tracks[t])\n",
    "            track_range = range(track_num*track_size + class_idx[t], (track_num+1)*track_size + class_idx[t])\n",
    "            valid_features[t*track_size:(t+1)*track_size] = features[track_range]\n",
    "            valid_labels[t*track_size:(t+1)*track_size] = labels[track_range]\n",
    "            delete_range[t] = track_range\n",
    "        # Remove the samples that were added to the validation set\n",
    "        train_features = np.delete(train_features, delete_range, axis=0) \n",
    "        train_labels = np.delete(train_labels, delete_range, axis=0) \n",
    "        \n",
    "        # Shuffle the validation and training sets\n",
    "        valid_features, valid_labels = shuffle(valid_features, valid_labels)\n",
    "        train_features, train_labels = shuffle(train_features, train_labels)\n",
    "        \n",
    "    else:\n",
    "        print('The split operation provided is not valid')\n",
    "        return\n",
    "    \n",
    "    return train_features, valid_features, train_labels, valid_labels\n",
    "\n",
    "\n",
    "def save_pickle(data_dict, filename):\n",
    "    '''Save the data for easy access'''\n",
    "    \n",
    "    pickle_file = filename + '.pickle'\n",
    "    # if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to ' + filename)\n",
    "    try:\n",
    "        with open(pickle_file, 'wb') as pfile:\n",
    "            pickle.dump(data_dict, pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "    print('Data saved to cache')\n",
    "    \n",
    "print('Helper Functions are Created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Visualize the German Traffic Signs Dataset. This is open ended, some suggestions include: plotting traffic signs images, plotting the count of each sign, etc. Be creative!\n",
    "\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- features -> the images pixel values, (width, height, channels)\n",
    "- labels -> the label of the traffic sign\n",
    "- sizes -> the original width and height of the image, (width, height)\n",
    "- coords -> coordinates of a bounding box around the sign in the image, (x1, y1, x2, y2). Based the original image (not the resized version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 39209\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Load the data and get a summary\n",
    "X_train, y_train, X_test, y_test = get_data()\n",
    "n_train, n_test, image_shape, n_classes = get_summary(X_train, y_train, X_test, y_test)\n",
    "class_count, class_idx = count_classes(y_train, n_classes)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "\n",
    "# Make copies of the original data to preserve the originals incase we need them later\n",
    "train_features = np.copy(X_train)\n",
    "train_labels = np.copy(y_train)\n",
    "test_features = np.copy(X_test)\n",
    "test_labels = np.copy(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Provide some data visualizations\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(y_train, n_classes)\n",
    "plt.title('Count of Sign Classes')\n",
    "plt.show()\n",
    "\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "for i in range(image_shape[0]):\n",
    "    for j in range(image_shape[1]):\n",
    "        x = np.append(x, [int(j)])\n",
    "        y = np.append(y, [int(i)])\n",
    "\n",
    "class_no = -1\n",
    "for i in range(n_train):\n",
    "    if y_train[i] != class_no:\n",
    "        class_no = y_train[i]\n",
    "        img = X_train[i]\n",
    "        img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        z = img_grayscale.flatten()\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x, y, z, zdir='z')\n",
    "        plt.title('Scatter Plot of Grayscale Vers. of Class ' + str(class_no) + ', image no. ' + str(i))\n",
    "        plt.show()\n",
    "        \n",
    "y_by_class = np.where(y_train == 14)\n",
    "y_by_class = y_by_class[0]\n",
    "X_by_class = X_train[y_by_class]\n",
    "counter = 0\n",
    "batch = X_by_class.shape[0]/10\n",
    "for img in X_by_class:\n",
    "    if counter%batch == 0:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.imshow(img)\n",
    "        plt.show()\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** For the dataset, I kept the images as RGB. I created a subset of the full dataset primarily to shorten the processing time of the model. In order to ensure that the model would have enough training samples per class, I only reduced the number of image samples from those classes that contained a number of samples above a certain threshold. In this case, that number was 600. If any class had more than 600 images, I would remove 3/4 of the tracks from that class. I made sure that each reduced class still had full tracks. \n",
    "\n",
    "I added synthetic data in order to help the model avoid overfitting on the existing training set. The two transforms I included are a rotation cw or ccw, and a Gaussian blur. The amount to rotate is randomly selected per image. Likewise, the Gaussian blur has a sigma value that is randomly selected per image. I applied the transforms to each class and made sure that the newly added synthetic images were grouped together with the images that they originated from.\n",
    "\n",
    "I normalized the image values by dividing each pixel value by 255. I normalize the input data in order to standardize the range of distributions of the input values. This allows the optimization algorithm to move towards a maxima more stably and quickly.\n",
    "\n",
    "For cross-validation, I followed a suggestion from a paper by Pierre Sermanet and Yann LeCun (a link to their paper is here: yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf) in which they selected a track from each class to include in their validation set. I removed the validation tracks from the training set and did not shuffle the training set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116337, 32, 32, 3) (1290, 32, 32, 3) (12630, 32, 32, 3) (1290, 32, 32, 3) (1290, 43) (116337, 43) (1290, 43) (12630, 43)\n"
     ]
    }
   ],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Some booleans for activating data modification functions\n",
    "grayscale = False\n",
    "yuv = False\n",
    "subset = False\n",
    "synth = True\n",
    "tfms = ['rotate', 'blur']\n",
    "norm = True\n",
    "ops = 'track_split'    # Extract a track per class to include in the validation set.\n",
    "\n",
    "## Modify the data set \n",
    "if grayscale:\n",
    "    # Make grayscale test and training images\n",
    "    train_features = make_gray(train_features)\n",
    "    test_features  = make_gray(test_features)\n",
    "\n",
    "if subset:\n",
    "    # Create a subset of the data\n",
    "    train_features, train_labels = make_subset(train_features, train_labels)\n",
    "\n",
    "if synth:\n",
    "    # Add synthetic data\n",
    "    train_features, train_labels = add_synthetic_data(train_features, train_labels, tfms=tfms)\n",
    "\n",
    "if norm:\n",
    "    # Normalize the test and training images\n",
    "    train_features = normalize_data(train_features)\n",
    "    test_features = normalize_data(test_features)\n",
    "\n",
    "# Split the training data into a training and validation set\n",
    "train_features, valid_features, train_labels, valid_labels = make_train_test(train_features, train_labels, \n",
    "                                                                             op=ops)\n",
    "\n",
    "# Select some data from the training set to run accuracy computation against\n",
    "train_dict_features, train_dict_labels = select_data(train_features, train_labels, \n",
    "                                                     subset_len=len(valid_features))\n",
    "    \n",
    "# Apply one-hot-encoding transform to the labels\n",
    "encoder = make_encoder(train_labels)\n",
    "train_labels = one_hot_transform(train_labels, encoder)\n",
    "valid_labels = one_hot_transform(valid_labels, encoder)                                                                      \n",
    "test_labels = one_hot_transform(test_labels, encoder)\n",
    "train_dict_labels = one_hot_transform(train_dict_labels, encoder)\n",
    "\n",
    "print(train_features.shape, valid_features.shape, test_features.shape,\n",
    "      train_dict_features.shape, train_labels.shape, valid_labels.shape, test_labels.shape, train_dict_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. If you generated additional data, why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** As I mentioned above, I added synthetic data in order to help the model avoid overfitting on the existing training set. The two transforms I included are a rotation cw or ccw, and a Gaussian blur. The amount to rotate is randomly selected per image. Likewise, the Gaussian blur has a sigma value that is randomly selected per image. I applied the transforms to each class and made sure that the newly added synthetic images were grouped together with the images that they originated from.\n",
    "\n",
    "For cross-validation, I followed a suggestion from a paper by Pierre Sermanet and Yann LeCun in which they selected a track from each class to include in their validation set. The paper stated that they were able to achieve better accuracy when they used this method to build their validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** I used a convolutional neural network (ConvNet) that includes 3 convolutional layers, followed by two fully-connected layers and a final classification layer. Compared to the LeNet architecture, mine has one more convolutional layers because I felt the extra layer could allow the network to detect more complicated strutures within each image. I used pooling only in the last layer because the lectures mentioned that pooling may remove too much information and that using dropout for regularization also prevents overfitting on the training data. I exclusively used valid padding because I felt it reduced the size of each image and that this would shorten computation time while still not removing as much information as pooling does. The detailed architecture is as follows:\n",
    "\n",
    "1st Convolutional Layer: \n",
    "Input is the data features, which is multiple 32x32x3 images.\n",
    "The filter is a 5x5 window, whose initial weights are a truncated normal with mean 0 and standard dev 0.05.\n",
    "The bias is originally all 0.\n",
    "I used a VALID padding.\n",
    "I used the ReLU activation.\n",
    "The output size is 28x28x6.\n",
    "\n",
    "2nd Convolutional Layer: \n",
    "The output of the 1st conv layer is the input here. Each input sample is 28x28x6.\n",
    "The filter is a 5x5 window, whose initial weights are a truncated normal with mean 0 and standard dev 0.05.\n",
    "The bias is originally all 0.\n",
    "I used a VALID padding.\n",
    "I used the ReLU activation.\n",
    "The output size is 24x24x16.\n",
    "\n",
    "3rd Convolutional Layer: \n",
    "The output of the 2nd conv layer is the input here. Each input sample is 24x24x16.\n",
    "The filter is a 5x5 window, whose initial weights are a truncated normal with mean 0 and standard dev 0.05.\n",
    "The bias is originally all 0.\n",
    "I used a VALID padding.\n",
    "I used the ReLU activation with 0.5 probability dropout.\n",
    "I use a 2x2 max pooling operation with a stride of 2.\n",
    "The output size is 10x10x32.\n",
    "\n",
    "Flattened Layer:\n",
    "The output of the 3rd conv layer is the input here. Each input sample is 10x10x32.\n",
    "This is converted into a flat 1D layer of size 3200.\n",
    "\n",
    "Fully Connected Layer 1:\n",
    "The flattened input is of size 3200.\n",
    "The weight matrix is a truncated normal with mean 0, standard dev 0.05, and shape 3200x120.\n",
    "The bias is originally all 0.\n",
    "I used the ReLu activation.\n",
    "The output size is 120.\n",
    "\n",
    "Fully Connected Layer 2:\n",
    "The output of the 1st FC layer is the input here.\n",
    "The weight matrix is a truncated normal with mean 0, standard dev 0.05, and shape 120x84.\n",
    "The bias is originally all 0.\n",
    "I used the ReLu activation.\n",
    "The output size is 84.\n",
    "\n",
    "Classification Layer:\n",
    "The output of the 2nd FC layer is the input here.\n",
    "The weight matrix is a truncated normal with mean 0, standard dev 0.05, and shape 84x43, where 43 is the number of classes in the dataset.\n",
    "The bias is originally all 0.\n",
    "I used the ReLu activation.\n",
    "The output size is 43.\n",
    "\n",
    "The output of the classification layer is run through a softmax operation to produce a vector of the probabilities of the input belonging to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Helper Functions Created\n"
     ]
    }
   ],
   "source": [
    "### The following are helper functions that are used to build the convolution neural network\n",
    "\n",
    "def conv_layer(input_layer, filter_size, num_input_channels, num_filters, stride=1, padding='SAME',\n",
    "               relu=False, pooling=False, pool_size=2, drop=False, keep_prob=0.5):\n",
    "    '''\n",
    "        Create a convolution layer with filter size, output channels, stride, and other parameters set\n",
    "        by the user.\n",
    "        \n",
    "        Arguments:\n",
    "        num_filters - number of output channels\n",
    "        relu - True if using relu, false otherwise\n",
    "        pooling - True if using pooling, false otherwise\n",
    "        pool_size - the H and W of the pooling filter\n",
    "        drop - True if using dropout, false otherwise\n",
    "        keep_prob - The amount of data to drop\n",
    "    '''\n",
    "    \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create filter weights with the given shape.\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    # print(weights.get_shape())\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = tf.Variable(tf.zeros(num_filters))\n",
    "\n",
    "    # Create the convolution operation\n",
    "    conv_layer = tf.nn.conv2d(input=input_layer,\n",
    "                             filter=weights,\n",
    "                             strides=[1, stride, stride, 1],\n",
    "                             padding=padding)\n",
    "\n",
    "    # Add the biases to the convolution output\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, biases)\n",
    "    \n",
    "    if relu:\n",
    "        # Create the ReLu activation function\n",
    "        conv_layer = tf.nn.relu(conv_layer)\n",
    "        \n",
    "    if drop:\n",
    "        # Use Dropout to prevent overfitting\n",
    "        conv_layer = tf.nn.dropout(conv_layer, keep_prob)\n",
    "        \n",
    "    if pooling == 'max':\n",
    "        # Create max-pooling\n",
    "        conv_layer = tf.nn.max_pool(value=conv_layer,\n",
    "                               ksize=[1, pool_size, pool_size, 1],\n",
    "                               strides=[1, pool_size, pool_size, 1],\n",
    "                               padding=padding)\n",
    "    if pooling == 'average':\n",
    "        # Create average-pooling\n",
    "        conv_layer = tf.nn.avg_pool(value=conv_layer,\n",
    "                               ksize=[1, pool_size, pool_size, 1],\n",
    "                               strides=[1, pool_size, pool_size, 1],\n",
    "                               padding=padding)\n",
    "\n",
    "    print(conv_layer.get_shape())\n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "    \n",
    "def fc_layer(input_layer, num_features, fc_size, relu=False, drop=False, keep_prob=0.5):\n",
    "    '''\n",
    "        Create a fully connected layer\n",
    "            \n",
    "        Arguments:\n",
    "        fc_size - Number of output channels\n",
    "        relu - True if using relu, false otherwise\n",
    "        drop - True if using dropout, false otherwise\n",
    "        keep_prob - The amount of data to drop\n",
    "    '''\n",
    "\n",
    "    shape=[num_features, fc_size]\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    biases = tf.Variable(tf.zeros(fc_size))\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    fc_layer = tf.nn.bias_add(tf.matmul(input_layer, weights), biases)\n",
    "    \n",
    "    if relu:\n",
    "        fc_layer = tf.nn.relu(fc_layer)\n",
    "    \n",
    "    if drop:\n",
    "        fc_layer = tf.nn.dropout(fc_layer, keep_prob)\n",
    "        \n",
    "    print(fc_layer.get_shape())\n",
    "    \n",
    "    return fc_layer\n",
    "\n",
    "print('Network Helper Functions Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 6)\n",
      "(?, 24, 24, 16)\n",
      "(?, 10, 10, 32)\n",
      "(?, 3200)\n",
      "(?, 120)\n",
      "(?, 84)\n",
      "(?, 43)\n",
      "Architecture Created\n"
     ]
    }
   ],
   "source": [
    "### Create a ConvNet\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "# Create the input data placeholders\n",
    "features = tf.placeholder(tf.float32, shape=[None, *train_features.shape[1:]])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, train_labels.shape[-1]])\n",
    "\n",
    "filter_size = 5\n",
    "output_size = 6\n",
    "\n",
    "# Conv Layer 1\n",
    "conv_layer_1 = conv_layer(features, filter_size, train_features.shape[-1], output_size, \n",
    "                          padding='VALID', relu=True)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv_layer_2 = conv_layer(conv_layer_1, filter_size, output_size, 16, \n",
    "                          padding='VALID', relu=True)\n",
    "\n",
    "# Conv Layer 3\n",
    "conv_layer_3 = conv_layer(conv_layer_2, filter_size, 16, 32, \n",
    "                          padding='VALID', pooling='max', relu=True, drop=True)\n",
    "\n",
    "# Flatten layer\n",
    "flat_layer = flatten(conv_layer_3)\n",
    "print(flat_layer.get_shape())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "num_features = int(flat_layer.get_shape()[-1])\n",
    "fc1_size = 120\n",
    "fc_layer_1 = fc_layer(flat_layer, num_features, fc1_size, relu=True)\n",
    "\n",
    "# Fully Connected Layer 2\n",
    "fc2_size = 84\n",
    "fc_layer_2 = fc_layer(fc_layer_1, fc1_size, fc2_size, relu=True)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = fc_layer(fc_layer_2, fc2_size, train_labels.shape[-1])\n",
    "\n",
    "print('Architecture Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization and Evaluation Functions Created\n"
     ]
    }
   ],
   "source": [
    "## Creating the Softmax predictions, loss, and optimizer functions\n",
    "prediction = tf.nn.softmax(output_layer)\n",
    "y_pred_cls = tf.argmax(prediction, 1)\n",
    "y_true_cls = tf.argmax(labels, 1)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer, labels))\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Construct the optimizer\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data, batch_size):\n",
    "    '''Calculate the accuracy of the model by classifying a dataset'''\n",
    "    \n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={features: batch_x, labels: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "# Get the top k predicted classes\n",
    "top_5 = tf.nn.top_k(input=prediction, k=5)\n",
    "\n",
    "def plot_confusion_matrix(cm, n_classes=None):\n",
    "    '''Plot the confusion matrix  of the true and predicted labels as an image.'''\n",
    "\n",
    "    plt.matshow(cm)  \n",
    "    if n_classes is None:\n",
    "        n_classes = cm.shape[0]\n",
    "        \n",
    "    # Make various adjustments to the plot.\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(n_classes)\n",
    "    plt.xticks(tick_marks, range(n_classes))\n",
    "    plt.yticks(tick_marks, range(n_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "print('Optimization and Evaluation Functions Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in new images taken from online or from a camera\n",
    "\n",
    "# Sort the list of the filenames of the new images\n",
    "sorted_files = sorted(os.listdir('cropped_images/'))\n",
    "print(sorted_files)\n",
    "\n",
    "# Load the new images into an array\n",
    "new_images = np.array([mpimg.imread('cropped_images/' + name) for name in sorted_files])\n",
    "\n",
    "# Make any modifications to the new images that were done to the training set\n",
    "if grayscale:\n",
    "    new_images = make_gray(new_images)\n",
    "    \n",
    "if norm:\n",
    "    new_images = normalize_data(new_images)\n",
    "    \n",
    "print(new_images.shape)\n",
    "\n",
    "# Associate labels with the new images\n",
    "new_images_labels = np.tile(np.array([0]), 10)    \n",
    "new_images_labels = np.append(new_images_labels, np.tile(np.array([1]), 8))\n",
    "new_images_labels = np.append(new_images_labels, np.tile(np.array([2]), 9))\n",
    "new_images_labels = np.append(new_images_labels, np.tile(np.array([3]), 9))\n",
    "new_images_labels = np.append(new_images_labels, np.tile(np.array([4]), 9))\n",
    "new_images_labels = np.append(new_images_labels, np.tile(np.array([5]), 8))\n",
    "\n",
    "print(new_images_labels)\n",
    "num_classes = max(new_images_labels) + 1\n",
    "\n",
    "new_images_labels = one_hot_transform(new_images_labels, encoder)\n",
    "print(new_images_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import shuffle from sklearn to shuffle training data after every epoch\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = 'model_rgb.ckpt'\n",
    "\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_features, labels: test_labels}\n",
    "train_feed_dict = {features: train_dict_features, labels: train_dict_labels}\n",
    "\n",
    "def run_model(train_features, train_labels, run_count, epochs, batch_size, save_file):\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        if run_count == 0:\n",
    "            print('Initiating the Model')\n",
    "            sess.run(init)\n",
    "        else:\n",
    "            print('Restoring a Saved Model')\n",
    "            saver.restore(sess, save_file)\n",
    "        \n",
    "        batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "        \n",
    "        # Training cycle\n",
    "        for epoch_i in range(epochs):\n",
    "            # Shuffle the training data\n",
    "            train_features, train_labels = shuffle(train_features, train_labels)\n",
    "            # Progress bar\n",
    "            batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "\n",
    "            # The training cycle\n",
    "            for batch_i in batches_pbar:\n",
    "                # Get a batch of training features and labels\n",
    "                batch_start = batch_i*batch_size\n",
    "                if batch_start >= len(train_features):\n",
    "                    break\n",
    "                batch_end = min(batch_start + batch_size, len(train_features))\n",
    "                batch_features = train_features[batch_start:batch_end]\n",
    "                batch_labels = train_labels[batch_start:batch_end]\n",
    "\n",
    "                # Run optimizer and get loss\n",
    "                _, l = sess.run(\n",
    "                    [optimizer, loss],\n",
    "                    feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "            # Check accuracy against Validation data\n",
    "            validation_accuracy = evaluate(valid_features, valid_labels, batch_size)\n",
    "            training_accuracy = evaluate(train_dict_features, train_dict_labels, batch_size)\n",
    "                  \n",
    "            # Display logs per epoch step\n",
    "            print(\"Epoch:\", '%04d' % (epoch_i+1), \"loss=\", \"{:.9f}\".format(l)) \n",
    "            print(\"Validation Accuracy=\", \"{:.9f}\".format(validation_accuracy), \n",
    "                  \"Training Accuracy=\", \"{:.9f}\".format(training_accuracy))\n",
    "\n",
    "        print(\"Optimization Finished!\") \n",
    "\n",
    "        test_accuracy = evaluate(test_features, test_labels, batch_size)\n",
    "        print('Test accuracy at {}'.format(test_accuracy))\n",
    "\n",
    "        # Check the accuracy of new images\n",
    "        new_data_accuracy, cls_true, cls_pred = sess.run([accuracy_operation, y_true_cls, y_pred_cls],\n",
    "                                                          feed_dict={features: new_images, labels: new_images_labels})\n",
    "        \n",
    "        print('New data accuracy at {}'.format(new_data_accuracy))\n",
    "        \n",
    "        # Check the confusion matrix of the predicted versus actual labels\n",
    "        cm = confusion_matrix(cls_true, cls_pred, labels=range(43))\n",
    "        plot_confusion_matrix(cm, 43)\n",
    "    \n",
    "        # Get the probabilies and labels of the top 5 predicted classifications\n",
    "        top_5_prob = sess.run(top_5, feed_dict={features: new_images, labels: new_images_labels})\n",
    "        \n",
    "        run_count += epochs\n",
    "        sess.close()\n",
    "        \n",
    "        return run_count, confusion_matrix(cls_true, cls_pred), cls_true, cls_pred, top_5_prob\n",
    "\n",
    "print('Model Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating the Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|██████████| 5817/5817 [04:54<00:00, 19.73batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 0.037677098\n",
      "Validation Accuracy= 0.901550378 Training Accuracy= 0.956589140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2/10: 100%|██████████| 5817/5817 [04:30<00:00, 23.12batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 loss= 0.061136287\n",
      "Validation Accuracy= 0.951937979 Training Accuracy= 0.979844956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3/10: 100%|██████████| 5817/5817 [04:22<00:00, 22.15batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 loss= 0.016174113\n",
      "Validation Accuracy= 0.953488366 Training Accuracy= 0.979069762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4/10: 100%|██████████| 5817/5817 [04:25<00:00, 21.87batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0004 loss= 0.339343786\n",
      "Validation Accuracy= 0.952713171 Training Accuracy= 0.983720926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5/10: 100%|██████████| 5817/5817 [04:36<00:00, 21.06batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 loss= 0.250322938\n",
      "Validation Accuracy= 0.944186038 Training Accuracy= 0.987596896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6/10: 100%|██████████| 5817/5817 [04:43<00:00, 19.50batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0006 loss= 0.004106718\n",
      "Validation Accuracy= 0.943410846 Training Accuracy= 0.985271315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7/10: 100%|██████████| 5817/5817 [04:36<00:00, 24.03batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 loss= 0.003670453\n",
      "Validation Accuracy= 0.967441854 Training Accuracy= 0.986821703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8/10: 100%|██████████| 5817/5817 [04:30<00:00, 23.04batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0008 loss= 0.019639447\n",
      "Validation Accuracy= 0.962015496 Training Accuracy= 0.985271314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9/10: 100%|██████████| 5817/5817 [04:24<00:00, 21.98batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0009 loss= 0.035604242\n",
      "Validation Accuracy= 0.952713171 Training Accuracy= 0.993798448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 5817/5817 [04:24<00:00, 21.98batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss= 0.004415096\n",
      "Validation Accuracy= 0.955038752 Training Accuracy= 0.989922478\n",
      "Optimization Finished!\n",
      "Model Saved to model_rgb.ckpt\n",
      "Validation accuracy at 0.9542635679244995\n",
      "Test accuracy at 0.9463974833488464\n",
      "[16  1 38 33 11 38 18 12 25 35 12  7 23  7  4  9 21 20 27 38  4 33  9  3  1\n",
      " 11 13 10  9 11  5 17 34 23  2 17  3 12 16  8  7 30 18 12 24 25  3 10 18  8\n",
      " 25 13 15  9 13 35  5 26  9 16 38 10  4  9 15  9 26  2  5 28 11 25 30 34  5\n",
      " 12  1 10 25 25 21 33 25  7 10 35  3  7 22 13  3  1  2 14 12 32  3 38  9 33\n",
      "  1 10  5 11 33  4 35 25 33  4  1 14 16 10 30  3 27 29  1 17 13  7  1  8  2\n",
      " 10 10 30  1  6 36  3 14 13 11 10 18 40  2 38 41  4  6 18 17 25  2 41 11 21\n",
      "  7 24 11 25 17  3  6  9  7  4 13 16  4 25 18  9 13 14 29 17 13 38 26 25 33\n",
      "  1  3 40 13  2  8  4 36 25 20 25 18  1 10  8 10 29 12 38 31  2  8 38 18 28\n",
      " 17  9  4  1 17  9  2 31 13 15 15 38 25  5 25 13 10  5  4 10  2  4  5  1 14\n",
      " 12 12  5  8 36 25 13 33 18 33 19 12 30  4 18 12 13 20  0 10 40  5  8 12 38\n",
      " 20 14  0 36 34 28 35 13 25 15 35 14 18 25  1 12  5 25  2 18 18 18 34  9 25\n",
      " 18 34 39 31  1  9 35 31 26  1  1 33 30 17 13  1 31 13 35  5  1 33 28 35 26\n",
      " 12  5  2 14  4  3 32  1  7 38 19 11 38 38  1 42  2 40 17  4  8  4  5  6 31\n",
      " 35  9 38  8  2  4 18  3 25 10  6  7 34  4 22 10 29  9  2 38 38 18  7 13 28\n",
      " 17  2 16 14 12 40 35  3 38 10  9 38 13 39  3 11  7 38 19 13 10 18  3  5 26\n",
      "  1 41 13  1 18 19 13 38  4 35 25 34 12 17  9  4 33 28  2  1  5  4 38  4 12\n",
      " 38 36 10  0 38 36  8 25  5  2 25 14  2 26 29 10 10 14  9  2  3  4 19  9 10\n",
      " 13 13 20 38 34 11 13 34 34 12  6 10 10  8  3 22 17  7 30 25  1 31 38 38  8\n",
      "  9 10  2 40  1 38 14  8 39  6 35 25 25 17  2 38  7 13 14  7  8 35  3  1 35\n",
      " 12 35 36 24 13 33  2 35  6  2 10 12 31  9 14 17 26  4  3 10  5 30  9 31 40]\n",
      "[16  1 38 33 11 38 18 12 25 35 12  7 23  7  4  9 21 20 27 38  4 33  9  3  1\n",
      " 11 13 10  9 11  5 17 34 31  2 17  3 12 16  8  7 30 18 12 24 37  3 10 31 40\n",
      " 39 13 15  9 13 35  5 26  9 16 38 10  4  9 15  9 26  2  5 28 11 25 30 34  5\n",
      " 12  1 10 11 37 21 33 25  7 10 35  3  7 22 13  3  1  2 14 12 32  3 38  9 33\n",
      "  1 10  5 11 33  4 35 25 33  4  1 14 16 10 11  3 27 29  1 17 13  7  1  8  2\n",
      " 10 10 31  1  6 36  3 14 13 11 10 18  7  2 38 41  4  6 18 17 27  2 41 11 21\n",
      "  7 24 11 25 17  3  6  9  7  4 13 16  4 27 18  9 13 14 29 17 13 38 26 25 33\n",
      "  1  3 40 13  2  8  4 36 25 20 25 18  1 10  8 10 29 12 38 31  2  8  8 17 28\n",
      " 17  9  4  1 17  9  2 31 13 15 15 38 25  2 25 13 10  5  4 10  2  4  5  1 14\n",
      " 12 12  5  8 36 25 13 33 18 33 19 12 30  4 18 12 13 20  0 10 40  2  8 12 38\n",
      " 20 14  0 36 34 28 35 13 25 15 35 14 18 25  1 12  5 25  2 18 24 18 34  9 25\n",
      " 18 34 39 31  1  9 10 31 26  1  1 33 31 17 13  1 31 13 35  5  1 33 28 35 26\n",
      " 12  5  2 14 25  3 32  1  7  1 19 11 38 38  2 42  2 40 17  4  8  4  5  6 31\n",
      " 35  9 38  8  2  4 18  3 25 10  3  7 34  4 11 10 29  9  2 38 38 18  7 13 28\n",
      " 17  2 16 14 12 40 35  3 12 10  9 38 13 39  3 11  7 38 19 13 10 18  3  5 22\n",
      "  1 41 13  1 18 19 13 38  4 35 25 34 12 17  9  4 33 28  2  1  5  4 38  4 12\n",
      " 38 36 10  0 38 36  8 25  2  2 25 14  2 26 29 10 10 14  9  2  3  2 19  9 10\n",
      " 13 13 20 38 34 11 13 34 34 12  6 10 10  8  3 22 17  7 23 25  1 31 38 38  8\n",
      "  9 10  2 40  1 40 14  8 39  1 35 25 25 17  2 38  7 13 14  7  8 35  3  1 35\n",
      " 12 35 36 24 13 33  2 35  6  2 10 12 31  9 14 17 26 10  3 10  2 11  9 31  7]\n"
     ]
    }
   ],
   "source": [
    "run_count = 0\n",
    "run_count = train_model(train_features, train_labels, run_count, 10, 20, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring a Saved Model\n"
     ]
    }
   ],
   "source": [
    "run_count = train_model(train_features, train_labels, run_count, 10, 20, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It would be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the dataset?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
